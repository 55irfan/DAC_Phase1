{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "EuegQdaqXHZb",
        "outputId": "8ab9031f-f4a1-48e7-d8fc-32c1440059dc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5fdd18555a3a>\"\u001b[0;36m, line \u001b[0;32m133\u001b[0m\n\u001b[0;31m    Testing there aren't any missing data\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 133)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import randint\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.grid_search import RandomizedSearchCV\n",
        "\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "\n",
        "\n",
        "from subprocess import check_output\n",
        "\n",
        "train_df = pd.read_csv('../input/survey.csv')\n",
        "\n",
        "\n",
        "print(train_df.shape)\n",
        "\n",
        "print(train_df.describe())\n",
        "\n",
        "print(train_df.info())\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)\n",
        "print(missing_data)\n",
        "\n",
        "train_df = train_df.drop(['comments'], axis= 1)\n",
        "train_df = train_df.drop(['state'], axis= 1)\n",
        "train_df = train_df.drop(['Timestamp'], axis= 1)\n",
        "\n",
        "train_df.isnull().sum().max() #just checking that there's no missing data missing...\n",
        "train_df.head(5)\n",
        "defaultInt = 0\n",
        "defaultString = 'NaN'\n",
        "defaultFloat = 0.0\n",
        "intFeatures = ['Age']\n",
        "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
        "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
        "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
        "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
        "                 'seek_help']\n",
        "floatFeatures = []\n",
        "\n",
        "for feature in train_df:\n",
        "    if feature in intFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultInt)\n",
        "    elif feature in stringFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultString)\n",
        "    elif feature in floatFeatures:\n",
        "        train_df[feature] = train_df[feature].fillna(defaultFloat)\n",
        "    else:\n",
        "        print('Error: Feature %s not recognized.' % feature)\n",
        "train_df.head(5)\n",
        "\n",
        "gender = train_df['Gender'].str.lower()\n",
        "gender = train_df['Gender'].unique()\n",
        "\n",
        "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
        "trans_str = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\"]\n",
        "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
        "\n",
        "for (row, col) in train_df.iterrows():\n",
        "\n",
        "    if str.lower(col.Gender) in male_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
        "\n",
        "    if str.lower(col.Gender) in female_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
        "\n",
        "    if str.lower(col.Gender) in trans_str:\n",
        "        train_df['Gender'].replace(to_replace=col.Gender, value='trans', inplace=True)\n",
        "stk_list = ['A little about you', 'p']\n",
        "train_df = train_df[~train_df['Gender'].isin(stk_list)]\n",
        "\n",
        "print(train_df['Gender'].unique())\n",
        "train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\n",
        "\n",
        "s = pd.Series(train_df['Age'])\n",
        "s[s<18] = train_df['Age'].median()\n",
        "train_df['Age'] = s\n",
        "s = pd.Series(train_df['Age'])\n",
        "s[s>120] = train_df['Age'].median()\n",
        "train_df['Age'] = s\n",
        "train_df['age_range'] = pd.cut(train_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)\n",
        "train_df['self_employed'] = train_df['self_employed'].replace([defaultString], 'No')\n",
        "print(train_df['self_employed'].unique())\n",
        "\n",
        "train_df['work_interfere'] = train_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
        "print(train_df['work_interfere'].unique())\n",
        "labelDict = {}\n",
        "for feature in train_df:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(train_df[feature])\n",
        "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "    train_df[feature] = le.transform(train_df[feature])\n",
        "    labelKey = 'label_' + feature\n",
        "    labelValue = [*le_name_mapping]\n",
        "    labelDict[labelKey] =labelValue\n",
        "\n",
        "for key, value in labelDict.items():\n",
        "    print(key, value)\n",
        "train_df = train_df.drop(['Country'], axis= 1)\n",
        "train_df.head()\n",
        "\n",
        "Testing there aren't any missing data\n",
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(20)\n",
        "print(missing_data)\n",
        "corrmat = train_df.corr()\n",
        "f, ax = plt.subplots(figsize=(12, 9))\n",
        "sns.heatmap(corrmat, vmax=.8, square=True);\n",
        "plt.show()\n",
        "\n",
        "k = 10 #number of variables for heatmap\n",
        "cols = corrmat.nlargest(k, 'treatment')['treatment'].index\n",
        "cm = np.corrcoef(train_df[cols].values.T)\n",
        "sns.set(font_scale=1.25)\n",
        "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(train_df[\"Age\"], bins=24)\n",
        "plt.title(\"Distribuition and density by Age\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.figure(figsize=(12,8))\n",
        "labels = labelDict['label_Gender']\n",
        "g = sns.countplot(x=\"treatment\", data=train_df)\n",
        "g.set_xticklabels(labels)\n",
        "\n",
        "plt.title('Total Distribuition by treated or not')\n",
        "\n",
        "o = labelDict['label_age_range']\n",
        "\n",
        "g = sns.factorplot(x=\"age_range\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\",  ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Age')\n",
        "\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "\n",
        "plt.show()\n",
        "o = labelDict['label_family_history']\n",
        "g = sns.factorplot(x=\"family_history\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Family History')\n",
        "ls\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "\n",
        "plt.show()\n",
        "o = labelDict['label_care_options']\n",
        "g = sns.factorplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Care options')\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "plt.show()\n",
        "o = labelDict['label_benefits']\n",
        "g = sns.factorplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Benefits')\n",
        "\n",
        "# replace legend labels\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "\n",
        "# Positioning the legend\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "plt.show()\n",
        "In [19]:\n",
        "o = labelDict['label_work_interfere']\n",
        "g = sns.factorplot(x=\"work_interfere\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", ci=None, size=5, aspect=2, legend_out = True)\n",
        "g.set_xticklabels(o)\n",
        "plt.title('Probability of mental health condition')\n",
        "plt.ylabel('Probability x 100')\n",
        "plt.xlabel('Work interfere')\n",
        "new_labels = labelDict['label_Gender']\n",
        "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
        "\n",
        "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
        "plt.show()\n",
        "scaler = MinMaxScaler()\n",
        "train_df['Age'] = scaler.fit_transform(train_df[['Age']])\n",
        "train_df.head()\n",
        "\n",
        "Spliltting the dataset\n",
        "feature_cols = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']\n",
        "X = train_df[feature_cols]\n",
        "y = train_df.treatment\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "methodDict = {}\n",
        "rmseDict = ()\n",
        "\n",
        "forest = ExtraTreesClassifier(n_estimators=250, random_state=0)\n",
        "\n",
        "forest.fit(X, y)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "labels = []\n",
        "for f in range(X.shape[1]):\n",
        "    labels.append(feature_cols[f])\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), labels, rotation='vertical')\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()\n",
        "def evalClassModel(model, y_test, y_pred_class, plot=False):\n",
        "\n",
        "    print('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "    print('Null accuracy:\\n', y_test.value_counts())\n",
        "\n",
        "    print('Percentage of ones:', y_test.mean())\n",
        "\n",
        "    print('Percentage of zeros:',1 - y_test.mean())\n",
        "\n",
        "\n",
        "    print('True:', y_test.values[0:25])\n",
        "    print('Pred:', y_pred_class[0:25])\n",
        "\n",
        "\n",
        "    TP = confusion[1, 1]\n",
        "    TN = confusion[0, 0]\n",
        "    FP = confusion[0, 1]\n",
        "    FN = confusion[1, 0]\n",
        "\n",
        "\n",
        "    sns.heatmap(confusion,annot=True,fmt=\"d\")\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
        "    print('Classification Accuracy:', accuracy)\n",
        "\n",
        "    print('Classification Error:', 1 - metrics.accuracy_score(y_test, y_pred_class))\n",
        "\n",
        "    false_positive_rate = FP / float(TN + FP)\n",
        "    print('False Positive Rate:', false_positive_rate)\n",
        "\n",
        "    print('Precision:', metrics.precision_score(y_test, y_pred_class))\n",
        "\n",
        "\n",
        "    print('AUC Score:', metrics.roc_auc_score(y_test, y_pred_class))\n",
        "\n",
        "\n",
        "    print('Cross-validated AUC:', cross_val_score(model, X, y, cv=10, scoring='roc_auc').mean())\n",
        "\n",
        "    print('First 10 predicted responses:\\n', model.predict(X_test)[0:10])\n",
        "\n",
        "\n",
        "    print('First 10 predicted probabilities of class members:\\n', model.predict_proba(X_test)[0:10])\n",
        "\n",
        "\n",
        "    model.predict_proba(X_test)[0:10, 1]\n",
        "\n",
        "\n",
        "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    if plot == True:\n",
        "        plt.rcParams['font.size'] = 12\n",
        "        plt.hist(y_pred_prob, bins=8)\n",
        "\n",
        "        plt.xlim(0,1)\n",
        "        plt.title('Histogram of predicted probabilities')\n",
        "        plt.xlabel('Predicted probability of treatment')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "    y_pred_prob = y_pred_prob.reshape(-1,1)\n",
        "    y_pred_class = binarize(y_pred_prob, 0.3)[0]\n",
        "\n",
        "\n",
        "    print('First 10 predicted probabilities:\\n', y_pred_prob[0:10])\n",
        "\n",
        "    roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
        "    if plot == True:\n",
        "        plt.figure()\n",
        "\n",
        "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.0])\n",
        "        plt.rcParams['font.size'] = 12\n",
        "        plt.title('ROC curve for treatment classifier')\n",
        "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_threshold(threshold):\n",
        "\n",
        "        print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])\n",
        "\n",
        "    predict_mine = np.where(y_pred_prob > 0.50, 1, 0)\n",
        "    confusion = metrics.confusion_matrix(y_test, predict_mine)\n",
        "    print(confusion)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "Tuning with cross validation score\n",
        "def tuningCV(knn):\n",
        "\n",
        "    k_range = list(range(1, 31))\n",
        "    k_scores = []\n",
        "    for k in k_range:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
        "        k_scores.append(scores.mean())\n",
        "    print(k_scores)\n",
        "    plt.plot(k_range, k_scores)\n",
        "    plt.xlabel('Value of K for KNN')\n",
        "    plt.ylabel('Cross-Validated Accuracy')\n",
        "    plt.show()\n",
        "Tuning with GridSearchCV\n",
        "def tuningGridSerach(knn):\n",
        "\n",
        "    k_range = list(range(1, 31))\n",
        "    print(k_range)\n",
        "\n",
        "    param_grid = dict(n_neighbors=k_range)\n",
        "    print(param_grid)\n",
        "\n",
        "        grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    grid.grid_scores_\n",
        "\n",
        "print(grid.grid_scores_[0].parameters)\n",
        "    print(grid.grid_scores_[0].cv_validation_scores)\n",
        "    print(grid.grid_scores_[0].mean_validation_score)\n",
        "\n",
        "    grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
        "    print(grid_mean_scores)\n",
        "\n",
        "    plt.plot(k_range, grid_mean_scores)\n",
        "    plt.xlabel('Value of K for KNN')\n",
        "    plt.ylabel('Cross-Validated Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    print('GridSearch best score', grid.best_score_)\n",
        "    print('GridSearch best params', grid.best_params_)\n",
        "    print('GridSearch best estimator', grid.best_estimator_)\n",
        "def tuningRandomizedSearchCV(model, param_dist):\n",
        "    rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
        "    rand.fit(X, y)\n",
        "    rand.grid_scores_\n",
        "\n",
        "        print('Rand. Best Score: ', rand.best_score_)\n",
        "    print('Rand. Best Params: ', rand.best_params_)\n",
        "\n",
        "    best_scores = []\n",
        "    for _ in range(20):\n",
        "        rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10)\n",
        "        rand.fit(X, y)\n",
        "        best_scores.append(round(rand.best_score_, 3))\n",
        "    print(best_scores)\n",
        "def tuningMultParam(knn):\n",
        "\n",
        "    k_range = list(range(1, 31))\n",
        "    weight_options = ['uniform', 'distance']\n",
        "\n",
        "    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
        "    print(param_grid)\n",
        "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
        "    grid.fit(X, y)\n",
        "\n",
        "\n",
        "    print(grid.grid_scores_)\n",
        "\n",
        "\n",
        "    print('Multiparam. Best Score: ', grid.best_score_)\n",
        "    print('Multiparam. Best Params: ', grid.best_params_)\n",
        "\n",
        "def randomForest():\n",
        "\n",
        "    forest = RandomForestClassifier(n_estimators = 20)\n",
        "\n",
        "    featuresSize = feature_cols.__len__()\n",
        "    param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, featuresSize),\n",
        "              \"min_samples_split\": randint(2, 9),\n",
        "              \"min_samples_leaf\": randint(1, 9),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "    tuningRandomizedSearchCV(forest, param_dist)\n",
        "\n",
        "\n",
        "    forest = RandomForestClassifier(max_depth = None, min_samples_leaf=8, min_samples_split=2, n_estimators = 20, random_state = 1)\n",
        "    my_forest = forest.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_class = my_forest.predict(X_test)\n",
        "\n",
        "    print('########### Random Forests ###############')\n",
        "\n",
        "    accuracy_score = evalClassModel(my_forest, y_test, y_pred_class, True)\n",
        "    methodDict['R. Forest'] = accuracy_score * 100\n",
        "\n",
        "randomForest()\n",
        "\n"
      ]
    }
  ]
}